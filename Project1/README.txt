Code written by Julia Adamczyk
Submission date: 9/23/2021
Note: I went to test the code to the ECC lab but they do not have the scipy package installed. 
      Therefore the code was tested partially on Linux, however, works fully on Windows.

1. Decision Tree

My decision tree is stored as a class. I also use two helper classes: Node, and Leaf for storing nodes of the decision tree. The Decision Tree class consists of the root - first node of the tree, max_depth - maximum height of the tree, and feature_dim - the dimension of the sample data. The Node class stores the feature index that the split is done on, and right and left subtree. The Leaf class contains the value of the leaf (i.e. 0.0 - no, and 1.0 - yes) and accuracy of the leaf.
Decision tree consists of multiple helper functions described here:
⦁	entropy(labels) - returns entropy of the set of labels. If the number of elements is less tha or equal to 1 the entropy is 0. else, the counts of each class are calculated using numpy unique function and then probabilities of each class is stored in the list. Then those probabilities are used to calculate the entropy of the set with the formula discussed in class. 
⦁	information_gain(before_split, yes, no) - calculates information gain over a split. Gets the probabilities of each split. Then returns: the entropy of the before_split minus the sum of probability of yes times the entropy of yes subset and probability of no times the entropy of no subset.
⦁	create_split(dataset, target_feature_index) - splits the data based on target_feature_index. For each sample in the dataset it checks if its value is 0 or 1 and assign it to the proper subset. Returns yes_split and no_split as two numpy arrays. 
⦁	get_best_split(X, Y)- iterates through each feature and finds best split for the data. Concatenates the sample features with the sample label. For each feature it creates a split using create_split function. If the length of one side is 0 then the split is skipped. Then it evaluates the information gain for the split. If the information gain is better than the current best information gain it updates all the variables that are returned. Returns the index of the best feature to split on, the information gain value of that split, the subset of yes samples, and the subset of no samples. 
⦁	build_tree(X,Y,counter)-recursively builds a tree based on training data. There are two possibilities that use the same logic for building a tree except they have different base conditions. The logic behind this function is deciding whether the node should be a leaf or a decision node. The conditions for a decision node are: (1) there are still at least 2 samples to be split, and (2) the information gain is not 0 (not all labels in a subset are the same). An extra condition is max_depth condition. If it's set to -1 then the tree will use only the two mentioned conditions to build a tree. If it's greater than zero then the termination will happen when the tree already have the max_depth value amount of decision nodes. The tree is built as follows: if the conditions are met it means that the node should be an instance of Node class. Therefore the best split is found. If the information gain is greater than 0 call build_tree on the false side and call build_tree on the true side. Return the decision node with the index of the feature that the split was made on, left branch, and, right branch. Else, return a Leaf with the most common value and calculated accuracy. If the max_depth is a positive integer the counter that is passed as a parameter to build tree keeps track of how many decision node levels are already in a tree. It is incremented after each creation.
⦁	train(X,Y) - calls build tree to initialize the root. Passes a counter as 1 (by creation of the tree we assume it already has 1 decision node).
⦁	print_tree(node) - prints the tree in preorder traversal manner. For debugging purposes.
⦁	functions that calculate accuracy - were used for debugging purposes. Now the accuracy is stored in each leaf so they are not used within the code.
⦁	test_set(X,Y) - returns the accuracy of the test set. Runs through all the samples in the test set and collects the predicted labels returned by the predict_single function. Then it calculates the number of correct predictions and returns the accuracy as the ratio of the number of correct predictions and the number of all predictions.
⦁	predict_single(x, node)- returns the predicted label of the sample. Recursively runs the sample through a tree to find the classification value. First, it checks if the node is a leaf. If it is it returns the value of the leaf. Then, it checks if the node is a decision node. If it is, it takes the feature index stored in the decision node and checks the value of the sample at that index. If it's zero it makes a recursive call on the false side, else it makes a recursive call on the true side.
The implementation of the functions specified in the project 1 prompt are hidden within the implementation of the DecisionTree class. In this case, the general functions make the calls to the decision tree class methods to provide the desired output.
⦁	DT_train_binary(X,Y,max_depth) - This function gets the dimentionality of the samples in the dataset, creates a DecisionTree object and initializes its max_depth and the number of features variables. Then, it calls the DecisionTree train() function. Returns the DecisionTree object.
⦁	DT_test_binary(X,Y,DT)-returns accuracy of the test set classification. Makes a call to DecisionTree test_set() function.
⦁	DT_make_prediction(x,DT)-returns a prediction label of the sample x. Checks if the dimensionality of the sample passed into a function is complient with the dimentionality of the samples used in training the decision tree. If yes, calls the DecisionTree predict_single function. Else, throws a message of incompatible dimensionality.

2. K Nearest Neighbors

My KNN algorithm works as follows. For each of the test sample (X_train), Euclidean distance to each of the training samples is calculated and stored in the list. Then the list is zipped with the training labels and sorted in ascending distance order. Then the algorithm runs through that list and sums K first train labels. Then it checks if the sum is greater or less than 0. If the sum is strictly greater than 0 then the positive label is assigned to the test sample. If the sum is equal or less than 0 then negative label is assigned to the test sample. All labels assigned to test samples are stored in the list. Once the procedure is performed for each sample in test set the accuracy is calculated. It is done by comparing the predicted labels to labels provided in the test set. The number of correctly predicted labels is calculated and divided by the number of samples in the test set. The result is returned as an accuracy of the KNN algorithm.

3. K-Means Clustering

My K-Means Clustering works as follows. Firstly, all the dim-1 axes that might have been created when loading the data are removed from the dataset. The sample dimension is calculated, current_mu and last_mu initialized as None. Then the means are initialized. The code handles an invalid entry of the means. If the means have wrong dimensions or are missing, the program calculates the max and min value of all dimensions and picks a random mean that is in between these two values. This is supposed to narrow down the possible integer values that the program could pick randomly. Then the program enters a loop. It will go until current_mu is not equal to last_mu. For each loop the clusters are stored in a dictionary of lists. Then inside that loop, for each point of the data set, the distance from each cluster mean is calculated and stored in the list. Then the minimum distance is used to determine which cluster should that sample be assigned to. After all points in the training set are processed the new_mean for each cluster is calculated. Then the means update is performed: last_mu is assigned to current_mu and current_mu is assigned to the new_mean. The loop terminates when last_mu == current_mu.