##############
Perceptron
##############

The function perceptron_train(X,Y) takes two arguments: X - data points, Y - labels associated with each data point. The function is implemented as follows. Firstly, the dimensionality of the data is check in order to handle different dimensionalities of the data. The shape of 0-axis of X numpy array is the number of samples while the shape of 1-axis of X numpy array is the dimensionality of the sample. Then, the values of the bias and weights are initialized to 0. bias is stored as an integer while weights are stored in a numpy array of size (sample_dim, ). The while loop goes until all predicted labels are correct. I am using function all to check if according labels in the predicted array are the same as the ones in the provided Y array. The loop is set in a epoch manner i.e. the for loop inside the while performs one epoch and assures that all the samples are tested against the updated weights. There are two helper functions used for readibility of the code. compute_activation_and_label(sample, weights, bias) returns the activation function given current sample, weights and bias and a predicted label. The activation is computed by taking the dot product of the weights and a sample and adding the bias term. Then, if the activation is greater than 0 the predited label is positive, otherwise the label is negative. Once the activation and the label are computed then the current predicted label for that sample is updated. Then if the condition for updating weight and bias (y*a <= 0) is true the weights and bias are updated using the second helper function - update_weights_and_bias(sample, label, weights, bias). This function implements the update equations: b = y + b, and for each weight: w = w + label * sample_coordinate. When the while loop terminates the perceptron parameters (w, b) are returned. 

The function perceptron_test(X_test, Y_test, w, b) takes the data and given weigths and bias and calculates the accuracy of the model on a given data. The function goes through the data points in a test set, predicts the label by using the compute_activation_and_label function and compares that prediction to the test label. If the predicted label matches the provided label then the count is incremented. Otherwise, the count is left untouched. The function returns the accuracy as the factor of the number of correctly predicted labels and the number of total labels in the set. 


###########
Gradient Descent
###########

My implementation of the gradient descent is very simple. The function takes in three arguments: the gradient function, the start point and the learning rate hyperparameter. The algorithm loops until the magnitude of the gradient is less than 0.0001. In order to calculate this, I use the numpy linalg norm function that takes the vector and calculates it's magnitude. Because the function gradient returns a single value if the feature is in 1D and a vector if the dimensionality is larger. Therefore it is necessary to compute the magnitude of the gradient. Inside the loop the step is taken. Start point is decremented by learning rate and the gradient of itself. Once the while loop is done the local minimum is found and returned.  
